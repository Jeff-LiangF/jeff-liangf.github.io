<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Feng(Jeff) Liang</title>

  <meta name="author" content="Feng(Jeff) Liang">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/tsinghua.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Feng(Jeff) Liang</name>
              </p>
              <p>I am a researcher at <a href="https://www.sensetime.com/en/about.html">Sensetime Research</a>, where I work on efficient machine learning, computer vision and their applications. Before becoming a full-time researcher, I obtained my master degree from <a href="https://www.tsinghua.edu.cn/en/index.htm">Tsingahu University</a>, where I was advised by <a href="https://www.researchgate.net/profile/Chun_Zhang">Prof. Chun Zhang</a> and <a href="http://www.ime.tsinghua.edu.cn/publish/ime/5910/2015/20150315142048923730191/20150315142048923730191_.html">Prof. Zhihua Wang</a>. I did my bachelors at <a href="http://english.hust.edu.cn/index.htm">Huazhong University of Science and Technology</a>.
              </p>
              <p>
                My current research interests lie in machine learning, particularly in efficient/auto deep learning, as well as their applications such as neural architecture search, hardware-software co-design, computer vision, etc. I'm fortunately working with <a href="https://wlouyang.github.io/">Prof. Wanli Ouyang</a> and <a href="https://yan-junjie.github.io/">Dr. Junjie Yan</a>.
              </p>
              <p style="text-align:center">
                <a href="mailto:liangfjeff@gmail.com">Email</a> &nbsp/&nbsp
                <a href="data/CV_JeffLiang.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=ecTFCUMAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://www.zhihu.com/people/liang-feng-53">Zhihu</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/jeff.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/jeff.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>News</heading>
                <ul>
<!--	              <li style="line-height:30px"> <a href="https://drive.google.com/open?id=1mTBOJefYp6_ZkWwgshcikQ_AI5nw1t7_">Paper</a> on 3D sceneflow prediction accepted at CVPR 2019.</li>-->
                  <li style="line-height:30px"> <b>July 2020:</b> Jeff is here!</li>
                </ul>
		    </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publications</heading>
              <!--<p>-->
                <!--I'm interested in computer vision, machine learning, optimization, and image processing.-->
                <!--Much of my research is about inferring the physical world (shape, motion, color, light, etc) from images.-->
                <!--Representative papers are <span class="highlight">highlighted</span>.-->
              <!--</p>-->
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/crnas_iclr2020.png" alt="crnas" width="280" height="200" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/1912.11234">
                <papertitle>Computation Reallocation for Object Detection</papertitle>
              </a>
              <br>
              <strong>Feng Liang</strong>,
              <a href="https://scholar.google.com/citations?user=rObgGWIAAAAJ&hl=en">Chen Lin</a>,
              <a href="https://scholar.google.com/citations?user=DEf4GkcAAAAJ&hl=zh-CN">Ronghao Guo</a>,
              <a href="https://msunming.github.io/">Ming Sun</a>,
              <a href="https://wuwei-ai.org/">Wei Wu</a>,
              <a href="https://yan-junjie.github.io/">Junjie Yan</a>,
              <a href="https://wlouyang.github.io/">Wanli Ouyang</a>
              <br>
              <em>ICLR</em>, 2020
              <br>
              <a href="https://arxiv.org/abs/1912.11234">arXiv</a>,
              <a href="data/crnas_iclr2020.bib">bibtex</a>
              <p></p>
              <p>We present CRNAS that can learn computation reallocation strategies across different feature resolution and spatial position diectly on the target detection dataset.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/fqn_cvpr2019.png" alt="fqn" width="280" height="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Li_Fully_Quantized_Network_for_Object_Detection_CVPR_2019_paper.pdf">
                <papertitle>Fully Quantized Network for Object Detection</papertitle>
              </a>
              <br>
              <a href="https://scholar.google.com/citations?user=2Ha91noAAAAJ&hl=en">Rundong Li</a>,
              <a href="https://scholar.google.com/citations?user=QOZnsYYAAAAJ&hl=zh-CN">Yan Wang</a>,
              <strong>Feng Liang</strong>,
              <a href="http://qinhongwei.com/academic/">Hongwei Qin</a>,
              <a href="https://yan-junjie.github.io/">Junjie Yan</a>,
              <a href="http://sist.shanghaitech.edu.cn/sist_en/2018/0820/c3846a31782/page.htm">Rui Fan</a>
              <br>
              <em>CVPR</em>, 2019
              <br>
              <a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Li_Fully_Quantized_Network_for_Object_Detection_CVPR_2019_paper.pdf">CVF</a>,
              <a href="data/fqn_cvpr2019.bib">bibtex</a>,
              <a href="https://github.com/lirundong/quant-pack">code</a>
              <p></p>
              <p>We apply our techniques to produce fully quantized 4-bit detectors based on RetinaNet and Faster RCNN, and show that these achieve state-of-the-art performance for quantized detectors.</p>
            </td>
          </tr>


        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Service</heading>
                <p>
                  Review papers for: IEEE TNNLS
                </p>
            </td>
          </tr>
        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                Thanks to <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron</a>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>